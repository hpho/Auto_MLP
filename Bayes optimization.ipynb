{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "keras-tuner : grid search / Random search / Bayes optimization / Hyper band\n",
    "*Hyper band의 경우 NN에 적절하지 않을 수도 있음. 동시에 여러 모델을 학습하다가 \n",
    "가장 효율이 떨어지는 모델을 절반씩 날리면서 가장 최후의 모델을 끝까지 학습 함으로서\n",
    "minimum loss를 찾는 알고리즘인데, 실제 데이터/optimization algorithm에 따라서\n",
    "학습 정도에 차이가 존재할 수 있다. 그래서 최근에는 베이즈 최적화와 하이퍼 밴드를\n",
    "결합한 최적화 알고리즘을 많이 사용하기도 한다.\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# !pip install -q -U keras-tuner\n",
    "import kerastuner as kt\n",
    "\n",
    "# load dataset\n",
    "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Normalize pixel values between 0 and 1\n",
    "img_train = img_train.astype('float32') / 255.0\n",
    "img_test = img_test.astype('float32') / 255.0\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n",
    "    model.add(keras.layers.Dense(units = hp_units, activation = 'relu'))\n",
    "    model.add(keras.layers.Dense(10))\n",
    "\n",
    "    # Tune the learning rate for the optimizer \n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "\n",
    "    model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True), \n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective = 'val_accuracy', \n",
    "                     max_epochs = 10,\n",
    "                     factor = 3,\n",
    "                     directory = 'my_dir',\n",
    "                     project_name = 'intro_to_kt')\n",
    "\n",
    "# tuner = kt.RandomSearch(\n",
    "#     build_model,\n",
    "#     objective='val_loss',\n",
    "#     max_trials=5)\n",
    "\n",
    "# tuner = kt.BayesianOptimization(\n",
    "#     build_model,\n",
    "#     objective='val_loss',\n",
    "#     max_trials=5)\n",
    "\n",
    "# tuner = kt.sklearn()\n",
    "\n",
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(*args, **kwargs):\n",
    "        IPython.display.clear_output(wait = True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기서 train/test 고정이 아니라 bagging / boosting 옵션 선택 했으면 좋겠다.\n",
    "# https://github.com/keras-team/keras-tuner\n",
    "# search 함수의 경우 fit과 똑같음\n",
    "\n",
    "batch_size - \n",
    "dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "gan.fit(dataset.take(100), epochs=1)\n",
    "\n",
    "tuner.search(img_train, label_train, epochs = 10, validation_data = (img_test, label_test), callbacks = [ClearTrainingOutput()])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "print(f\"\"\"The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "    layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "    is {best_hps.get('learning_rate')}.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(img_train, label_train, epochs = 10, validation_data = (img_test, label_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
